---
layout: post

title: chatglm3

categories: [AI]





---



# ChatGLM3-6B

快速上手部署运行大模型，使用cpu运行，需要32G以上的内存

运行系统：linux 依赖环境：docker

源代码：[THUDM/ChatGLM3: ChatGLM3](https://github.com/THUDM/ChatGLM3)

模型：[THUDM/chatglm3-6b · Hugging Face](https://huggingface.co/THUDM/chatglm3-6b)

步骤一：下载代码和模型，非常耗时：

```
git clone https://github.com/THUDM/ChatGLM3
git lfs install
git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git
```

lfs 是git下载大文件需要的组件，这里我在clone的时候经常卡住，于是选择了在网页上依次手动点击文件下载

![image-20231228150043471](https://github.com/yimacro/yimacro.github.io/assets/38414606/4e51515d-fe1a-4d9e-acd1-8d291626a28f)


步骤二：准备依赖镜像

因为本地cpu、内存资源不够需要上传到服务器运行于是使用docker制作镜像上传

Dockerfile

```
FROM python:3.11.4-slim-bullseye

RUN pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple && pip install --upgrade pip && \
    pip install protobuf 'transformers>=4.30.2' cpm_kernels 'torch>=2.0' gradio mdtex2html sentencepiece accelerate

WORKDIR /app
```

docker build model_base . 

这里很容易出现网络问题，我把制作的镜像上传到了docker hub(只下载了模型的依赖，源代码的依赖没有下载)

```
docker pull yimacro/chatglm3:base
```

步骤三：打包上传镜像、模型和源代码(文件大，网络慢，非常耗时)

```
docker save d2635a9c847c > model.tar
tar -zcvf chatglm3-6b.tar.gz chatglm3-6b/
tar -zcvf ChatGLM3-main.tar.gz ChatGLM3-main/
```

因为，文件比较大，很容易出现磁盘不够的现象，随时注意空间的使用

步骤四：环境准备

```
docker load < model.tar  //加载镜像
docker run -it --cpus=16 -m=40000m image-id /bin/bash //运行镜像,限制cpu、内存使用
docker cp chatglm3-6b containerid:/app //复制模型文件到镜像
```

步骤五：模型运行

```
docker start containerid
docker attach containerid//进入有模型的镜像
python

from transformers import AutoTokenizer, AutoModel
tokenizer = AutoTokenizer.from_pretrained("/app/chatglm3-6b", trust_remote_code=True)
model = AutoModel.from_pretrained("/app/chatglm3-6b", trust_remote_code=True).float()
model = model.eval()
response, history = model.chat(tokenizer, "你好", history=[])
print(response)
response, history = model.chat(tokenizer, "晚上睡不着应该怎么办", history=history)
print(response)

```

![image-20231228151849281](https://github.com/yimacro/yimacro.github.io/assets/38414606/d610e1ea-48f9-4d1f-895b-8117a6d23616)




参考：[清华开源语言大模型ChatGLM3部署实战](https://blog.csdn.net/Silver__Wolf/article/details/134247535)




from: *[Yimacro](https://yimacro.github.io/)    关注：[公众号](https://mp.weixin.qq.com/s?__biz=Mzg4Njc0NTY0OQ==&mid=2247483761&idx=1&sn=d6b86854330d02875d47f7dde2c543aa&chksm=cf95be2ff8e237393e99a7d99c18280195d9006e407c5d3b0121413017d28305f84cffb1cd83#rd)*

